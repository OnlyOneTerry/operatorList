{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2binary ={}#int2binary[3]=[0,0,0,0,0,0,1,1]\n",
    "binary_dim = 8\n",
    "\n",
    "largest_number = pow(2,binary_dim)\n",
    "\n",
    "binary = np.unpackbits(\n",
    "           np.array([range(largest_number)],dtype=np.uint8).T,axis = 1)\n",
    "#建立字典\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "    \n",
    "def binary_generation(numbers,reverse = False):\n",
    "    binary_x = np.array([int2binary[num] for num in numbers],dtype=np.uint8)\n",
    "    \n",
    "    if reverse:\n",
    "        binary_x = np.fliplr(binary_x)\n",
    "    return binary_x\n",
    "\n",
    "def batch_generation(batch_size,largest_number):\n",
    "#     随机生成batch_size 个数\n",
    "        n1 = np.random.randint(0,largest_number//2,batch_size)\n",
    "        n2 = np.random.randint(0,largest_number//2,batch_size)\n",
    "        add = n1 + n2\n",
    "        \n",
    "        binary_n1 = binary_generation(n1,True)\n",
    "        binary_n2 = binary_generation(n2,True)\n",
    "        binary_n3 = binary_generation(add,True)\n",
    "        batch_y = binary_generation(add,True)\n",
    "        \n",
    "        batch_x = np.dstack((binary_n1,binary_n2))\n",
    "        return batch_x,batch_y,n1,n2,add\n",
    "\n",
    "def binary2int(binary_array):\n",
    "    out = 0\n",
    "    for index,x in enumerate(reversed(binary_array)):\n",
    "        out += x*pow(2,index)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 64\n",
    "lstm_size = 20\n",
    "lstm_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,binary_dim,2],name='input_x')\n",
    "\n",
    "y_ = tf.placeholder(tf.float32,[None,binary_dim],name='input_y')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32,name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "\n",
    "drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
    "\n",
    "def lstm_cell():\n",
    "    return tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(lstm_layers)])\n",
    "\n",
    "initial_state = cell.zero_state(batch_size,tf.float32)\n",
    "\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell,x,initial_state=initial_state)\n",
    "\n",
    "# build output layer\n",
    "weights  = tf.Variable(tf.truncated_normal([lstm_size,1],stddev=0.01))\n",
    "bias = tf.zeros([1])\n",
    "\n",
    "outputs = tf.reshape(outputs,[-1,lstm_size])\n",
    "\n",
    "logits = tf.sigmoid(tf.matmul(outputs,weights))\n",
    "\n",
    "predictions = tf.reshape(logits,[-1,binary_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.losses.mean_squared_error(y_,predictions)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:1000,Loss:0.03537212312221527\n",
      "iter:2000,Loss:0.0010282548610121012\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "[1 1 1 0 0 1 0 0]:228\n",
      "\n",
      "[0 0 1 0 0 0 0 1]:33\n",
      "[0 0 1 0 1 0 1 0]:42\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "\n",
      "[0 0 0 1 0 1 1 0]:22\n",
      "[0 0 0 0 1 1 1 1]:15\n",
      "[0 0 1 0 0 1 0 1]:37\n",
      "\n",
      "[0 1 1 1 1 1 1 1]:127\n",
      "[0 0 0 1 0 1 0 1]:21\n",
      "[1 0 0 1 0 1 0 0]:148\n",
      "\n",
      "[0 1 0 1 0 1 0 0]:84\n",
      "[0 1 1 1 1 0 1 1]:123\n",
      "[1 1 0 0 1 1 1 1]:207\n",
      "\n",
      "[0 0 1 1 0 0 0 0]:48\n",
      "[0 1 0 1 0 0 0 1]:81\n",
      "[1 0 0 0 0 0 0 1]:129\n",
      "\n",
      "[0 1 1 0 0 1 0 1]:101\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "[1 0 1 1 0 0 0 0]:176\n",
      "\n",
      "[0 1 1 0 0 1 1 1]:103\n",
      "[0 0 0 1 0 1 1 0]:22\n",
      "[0 1 1 1 1 1 0 1]:125\n",
      "\n",
      "[0 1 1 0 1 0 1 0]:106\n",
      "[0 0 1 1 0 1 1 0]:54\n",
      "[1 0 1 0 0 0 0 0]:160\n",
      "\n",
      "[0 0 1 0 1 1 1 0]:46\n",
      "[0 1 0 1 1 1 1 0]:94\n",
      "[1 0 0 0 1 1 0 0]:140\n",
      "\n",
      "[0 1 1 0 1 1 1 1]:111\n",
      "[0 1 1 1 1 1 0 1]:125\n",
      "[1 1 1 0 1 1 0 0]:236\n",
      "\n",
      "[0 1 1 0 0 0 1 0]:98\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "[1 1 0 1 0 1 1 0]:214\n",
      "\n",
      "[0 0 1 1 0 1 1 1]:55\n",
      "[0 1 0 1 0 1 0 0]:84\n",
      "[1 0 0 0 1 0 1 1]:139\n",
      "\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "[0 1 1 1 1 1 0 0]:124\n",
      "[1 1 0 0 0 1 1 1]:199\n",
      "\n",
      "[0 0 1 1 1 1 0 1]:61\n",
      "[0 1 0 0 0 0 1 0]:66\n",
      "[0 1 1 1 1 1 1 1]:127\n",
      "\n",
      "[0 1 0 1 0 1 1 1]:87\n",
      "[0 1 1 0 1 0 1 0]:106\n",
      "[1 1 0 0 0 0 0 1]:193\n",
      "\n",
      "[0 0 0 1 0 1 0 0]:20\n",
      "[0 0 0 0 1 1 0 0]:12\n",
      "[0 0 1 0 0 0 0 0]:32\n",
      "\n",
      "[0 1 1 1 1 0 0 0]:120\n",
      "[0 0 0 0 1 0 1 1]:11\n",
      "[1 0 0 0 0 0 1 1]:131\n",
      "\n",
      "[0 0 0 1 0 1 1 1]:23\n",
      "[0 1 1 0 1 0 1 0]:106\n",
      "[1 0 0 0 0 0 0 1]:129\n",
      "\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "[0 1 1 0 1 1 1 0]:110\n",
      "[1 0 1 1 1 0 0 1]:185\n",
      "\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "[0 1 0 0 1 0 0 0]:72\n",
      "[0 1 1 0 0 1 0 0]:100\n",
      "\n",
      "[0 0 1 1 0 0 1 1]:51\n",
      "[0 0 1 1 1 1 1 0]:62\n",
      "[0 1 1 1 0 0 0 1]:113\n",
      "\n",
      "[0 0 1 1 1 0 0 1]:57\n",
      "[0 0 1 1 1 0 1 1]:59\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "\n",
      "[0 0 1 1 1 0 1 1]:59\n",
      "[0 1 0 0 1 1 0 0]:76\n",
      "[1 0 0 0 0 1 1 1]:135\n",
      "\n",
      "[0 0 0 1 0 0 1 1]:19\n",
      "[0 0 0 0 0 0 1 0]:2\n",
      "[0 0 0 1 0 1 0 1]:21\n",
      "\n",
      "[0 0 1 1 0 1 0 0]:52\n",
      "[0 0 0 1 0 0 1 1]:19\n",
      "[0 1 0 0 0 1 1 1]:71\n",
      "\n",
      "[0 1 0 1 0 0 1 1]:83\n",
      "[0 0 0 0 1 1 0 0]:12\n",
      "[0 1 0 1 1 1 1 1]:95\n",
      "\n",
      "[0 1 0 0 1 1 1 1]:79\n",
      "[0 0 1 1 0 0 0 0]:48\n",
      "[0 1 1 1 1 1 1 1]:127\n",
      "\n",
      "[0 0 0 1 1 0 0 1]:25\n",
      "[0 0 0 1 1 0 0 0]:24\n",
      "[0 0 1 1 0 0 0 1]:49\n",
      "\n",
      "[0 0 0 1 1 1 1 1]:31\n",
      "[0 1 1 1 1 0 0 0]:120\n",
      "[1 0 0 1 0 1 1 1]:151\n",
      "\n",
      "[0 0 0 0 1 1 1 0]:14\n",
      "[0 1 0 1 0 1 1 1]:87\n",
      "[0 1 1 0 0 1 0 1]:101\n",
      "\n",
      "[0 1 0 1 0 1 1 1]:87\n",
      "[0 1 0 0 1 1 0 1]:77\n",
      "[1 0 1 0 0 1 0 0]:164\n",
      "\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "[0 1 1 1 1 1 0 0]:124\n",
      "[1 0 0 1 1 0 0 0]:152\n",
      "\n",
      "[0 1 1 1 1 1 0 1]:125\n",
      "[0 1 1 0 0 0 1 0]:98\n",
      "[1 1 0 1 1 1 1 1]:223\n",
      "\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "[0 0 0 0 1 0 0 1]:9\n",
      "[0 0 1 0 0 1 0 1]:37\n",
      "\n",
      "[0 0 0 0 0 1 1 0]:6\n",
      "[0 0 1 1 1 1 0 0]:60\n",
      "[0 1 0 0 0 0 1 0]:66\n",
      "\n",
      "[0 0 0 0 0 1 0 0]:4\n",
      "[0 1 1 1 0 1 0 1]:117\n",
      "[0 1 1 1 1 0 0 1]:121\n",
      "\n",
      "[0 0 1 0 1 0 1 0]:42\n",
      "[0 1 1 0 0 1 0 0]:100\n",
      "[1 0 0 0 1 1 1 0]:142\n",
      "\n",
      "[0 1 0 1 0 0 0 0]:80\n",
      "[0 0 0 0 1 0 1 1]:11\n",
      "[0 1 0 1 1 0 1 1]:91\n",
      "\n",
      "[0 0 1 1 1 0 1 1]:59\n",
      "[0 1 0 0 1 0 1 0]:74\n",
      "[1 0 0 0 0 1 0 1]:133\n",
      "\n",
      "[0 0 1 1 0 1 1 1]:55\n",
      "[0 0 1 0 1 0 1 0]:42\n",
      "[0 1 1 0 0 0 0 1]:97\n",
      "\n",
      "[0 0 1 0 1 0 1 1]:43\n",
      "[0 0 1 1 1 1 1 0]:62\n",
      "[0 1 1 0 1 0 0 1]:105\n",
      "\n",
      "[0 1 0 1 1 0 1 1]:91\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[1 1 0 0 1 0 1 1]:203\n",
      "\n",
      "[0 0 1 1 0 0 1 1]:51\n",
      "[0 1 1 1 0 0 0 1]:113\n",
      "[1 0 1 0 0 1 0 0]:164\n",
      "\n",
      "[0 0 0 0 1 1 0 1]:13\n",
      "[0 0 0 1 1 0 1 0]:26\n",
      "[0 0 1 0 0 1 1 1]:39\n",
      "\n",
      "[0 1 0 0 1 0 0 0]:72\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[1 0 1 1 1 0 0 0]:184\n",
      "\n",
      "[0 1 1 1 0 0 1 0]:114\n",
      "[0 1 0 0 0 1 1 1]:71\n",
      "[1 0 1 1 1 0 0 1]:185\n",
      "\n",
      "[0 0 0 1 0 1 0 1]:21\n",
      "[0 1 1 1 0 0 1 1]:115\n",
      "[1 0 0 0 1 0 0 0]:136\n",
      "\n",
      "[0 0 1 0 0 0 0 0]:32\n",
      "[0 1 1 0 1 0 0 0]:104\n",
      "[1 0 0 0 1 0 0 0]:136\n",
      "\n",
      "[0 1 0 0 0 0 1 1]:67\n",
      "[0 1 0 1 1 0 0 1]:89\n",
      "[1 0 0 1 1 1 0 0]:156\n",
      "\n",
      "[0 0 0 1 0 1 1 1]:23\n",
      "[0 0 0 1 0 1 0 0]:20\n",
      "[0 0 1 0 1 0 1 1]:43\n",
      "\n",
      "[0 1 1 0 0 0 0 1]:97\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[1 1 0 1 0 0 0 1]:209\n",
      "\n",
      "[0 0 0 0 0 0 0 0]:0\n",
      "[0 1 0 1 0 0 1 0]:82\n",
      "[0 1 0 1 0 0 1 0]:82\n",
      "\n",
      "[0 1 1 1 1 1 1 1]:127\n",
      "[0 0 1 0 0 0 0 0]:32\n",
      "[1 0 0 1 1 1 1 1]:159\n",
      "\n",
      "[0 0 0 1 1 0 0 0]:24\n",
      "[0 1 0 0 0 1 1 0]:70\n",
      "[0 1 0 1 1 1 1 0]:94\n",
      "\n",
      "[0 1 1 0 0 0 0 0]:96\n",
      "[0 1 1 1 0 1 1 1]:119\n",
      "[1 1 0 1 0 1 1 1]:215\n",
      "\n",
      "[0 1 0 0 0 1 0 0]:68\n",
      "[0 1 1 0 1 1 0 1]:109\n",
      "[1 0 1 1 0 0 0 1]:177\n",
      "\n",
      "[0 1 0 1 1 1 1 1]:95\n",
      "[0 0 0 0 1 0 0 0]:8\n",
      "[0 1 1 0 0 1 1 1]:103\n",
      "\n",
      "[0 0 1 0 0 0 1 1]:35\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "[1 0 0 1 0 1 1 1]:151\n",
      "\n",
      "[0 0 1 0 1 0 1 1]:43\n",
      "[0 0 0 0 0 0 0 1]:1\n",
      "[0 0 1 0 1 1 0 0]:44\n",
      "\n",
      "[0 1 0 1 0 0 1 0]:82\n",
      "[0 0 1 0 0 0 1 1]:35\n",
      "[0 1 1 1 0 1 0 1]:117\n",
      "\n",
      "[0 0 1 0 1 0 1 0]:42\n",
      "[0 1 0 1 1 1 1 0]:94\n",
      "[1 0 0 0 1 0 0 0]:136\n",
      "\n",
      "[0 0 1 1 1 0 1 0]:58\n",
      "[0 1 0 1 0 1 0 1]:85\n",
      "[1 0 0 0 1 1 1 1]:143\n",
      "\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "[0 0 0 1 0 1 1 1]:23\n",
      "[0 1 1 0 0 0 1 0]:98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "steps = 2000\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    iteration = 1\n",
    "    for i in range(steps):\n",
    "        input_x,input_y,_,_,_ = batch_generation(batch_size,largest_number)\n",
    "        _,loss = sess.run([optimizer,cost],feed_dict = {x:input_x,y_:input_y,keep_prob:0.5})\n",
    "        \n",
    "        if iteration % 1000 == 0:\n",
    "            print(\"iter:{},Loss:{}\".format(iteration,loss))\n",
    "        iteration +=1\n",
    "#     训练结束 ，进行测试\n",
    "    val_x,val_y,n1,n2,add = batch_generation(batch_size,largest_number)\n",
    "    result = sess.run(predictions,feed_dict={x:val_x,y_:val_y,keep_prob:1.0})\n",
    "    \n",
    "    result = np.fliplr(np.round(result))\n",
    "    result = result.astype(np.int32)\n",
    "    \n",
    "    for b_x,b_p,a,b,add in zip(np.fliplr(val_x),result,n1,n2,add):\n",
    "        print('{}:{}'.format(b_x[:,0],a))\n",
    "        print('{}:{}'.format(b_x[:,1],b))\n",
    "        print('{}:{}\\n'.format(b_p,binary2int(b_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
