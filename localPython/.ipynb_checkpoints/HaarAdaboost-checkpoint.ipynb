{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 特征是什么 2 判决 3 得到判决\n",
    "# haar特征  像素运算的结果 （具体值 向量 矩阵 多维）\n",
    "# 1 haar模板 从上到下从左到右遍历图片 size 100*100  ，特征模板大小为10*10  移动的步长为 step = 10 则有100 次模板计算\n",
    "#  1,图片大小100*100 2,模板大小10*10 3移动步长 step=10  4使用基础模板1\n",
    "#  模板不仅有移动 还可以缩放  10*10 ---》11*11  缩放20级\n",
    "\n",
    "# 举例图片打下：1080*720 滑动步长：2 模板大小 10*10\n",
    "# 计算量  14模板*20缩放*（1080/2*720/2）*(100点加减运算)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  haar + adaboost face \n",
    "# 苹果 苹果 苹果  香蕉 （负样本被加强）\n",
    "# 0.1 0.1 0.1     0.5\n",
    "#  训练终止条件  1 通过循环次数for count  2 通过误差概率p  达到某个范围\n",
    "#  1. 分类器的结构 2  adaboost 计算过程 3 xml 文件结构\n",
    "#  haar > T1   and  haar > T2  (级联分类器) 2个强分类器 一般通过15-20 个门限才被认为是目标\n",
    "#  3个强分类器 1 特征x1 阈值t1 2 特征x2 阈值t2 3 特征x3 阈值t3  \n",
    "# x1>t1  and x2>t2  and x3>t3  表明通过3个强分类器  ---》目标  苹果\n",
    "# 强分类器的作用是判决，例如判决结果是不是苹果\n",
    "# 弱分类器的作用用来计算强分类器的特征 x1 x2 x3\n",
    "#  x2 = sum(y1,y2,y3) x2特征由三个弱分类器组成y,y2,y3\n",
    "#  y1弱分类器特征计算  由若干个node节点组成\n",
    "#  node\n",
    "# 在opencv中一个弱分类器最多支持3个haar特征，每个haar特征构成一个节点\n",
    "# 1node节点的  haar1  > nodeT1(阈值判决门限)   z1 = a1\n",
    "# 1node节点的  haar1  < nodeT1(阈值判决门限)   z1 = a2\n",
    "#2node节点 3 node节点同上 ....\n",
    "# z = sum(z1,z2,z3) > T(弱分类器阈值判决门限)  y1   =  AA\n",
    "# z = sum(z1,z2,z3) < T(弱分类器阈值判决门限)  y1   =  BB\n",
    "# 总结\n",
    "# haar->node  z1 z2 z3  ---> Z = sum(z1,z2,z3)\n",
    "# Z>T  y1 y2 y3  由节点特征计算得到弱分类器特征\n",
    "# X = sum(y1,y2,y3) > T1  obj 由弱分类器特征得到强分类器特征，对强分类器进行阈值判决得到 目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face= 1\n",
      "eye= 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1, load xml  2, load jpg 3 haar gray 4 detect 5 draw\n",
    "import cv2\n",
    "import numpy as np\n",
    "face_xml = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_xml = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# load jpg\n",
    "img = cv2.imread(\"D:/images/lena.jpg\")\n",
    "cv2.imshow('src',img)\n",
    "# haar gray\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# detect face\n",
    "faces = face_xml.detectMultiScale(gray,1.3,5)\n",
    "print('face=',len(faces))\n",
    "# draw\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_face = gray[y:y+h,x:x+w]\n",
    "    roi_color = img[y:y+h,x:x+w]\n",
    "#     gray\n",
    "    eyes = eye_xml.detectMultiScale(roi_face)\n",
    "    print('eye=',len(eyes))\n",
    "    for(e_x,e_y,e_w,e_h) in eyes:\n",
    "        cv2.rectangle(roi_color,(e_x,e_y),(e_x+e_w,e_y+e_h),(0,255,0),2)\n",
    "cv2.imshow('dst',img)\n",
    "cv2.waitKey(0)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
